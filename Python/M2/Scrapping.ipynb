{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import os \n",
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cdiscount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav.get(\"https://www.cdiscount.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cookies(soupe:BS):\n",
    "    \"\"\"Fonction permettant de passer l'étape des cookies sur CDiscount\n",
    "    \"\"\"\n",
    "    elem = soupe.find(text=\"Accepter\")\n",
    "    bouton = nav.find_element(By.ID, \"footer_tc_privacy_button_3\")\n",
    "    bouton.click()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche():\n",
    "    \"\"\"Fonction permettant de taper l'élement de recherche voulu et de lancer la recherche\n",
    "    \"\"\"\n",
    "    recherche = nav.find_element(By.XPATH, \"//div[@class='hSrcInput']/input[1]\")\n",
    "    #recherche.screenshot(\"recherche.png\")\n",
    "    recherche.send_keys(\"Ordinateur portable\")\n",
    "    sleep(3)\n",
    "    recherche.send_keys(Keys.ENTER)\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuf():\n",
    "    code = nav.page_source\n",
    "    soupe=BS(code) \n",
    "    neuf = soupe.find_all(attrs={\"value\": [\"Neuf ou occasion/neuf\"]})[0]\n",
    "    neuf = neuf.parent.get_text(strip=True)\n",
    "    neuf_b = nav.find_element(By.XPATH, f\"//span[@title='{neuf}']\") \n",
    "    #neuf_b.screenshot(\"neuf_b.png\")\n",
    "    neuf_b.click()\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retour arrière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retour():\n",
    "    \"\"\"Fonction permettant de revenir en arrière, driver.back() plus facile.\n",
    "    \"\"\"\n",
    "    code= nav.page_source\n",
    "    soupe = BS(code)\n",
    "    #retour = soupe.find(text = \"Retour aux offres\")\n",
    "    retour = nav.find_element(By.CLASS_NAME, \"bcBack\")\n",
    "    #retour.screenshot(\"retour.png\")\n",
    "    retour.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plus simple...\n",
    "nav.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changer de page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changer_page(j:int):\n",
    "    \"\"\"Fonction permettant de changer de page. Soit on passe à la page suivante(suivante) soit on peut \n",
    "    revenir à la prècèdente (retour). Permet de changer de page malgrès le changement de code html entre la\n",
    "    page 1 et les suivantes\n",
    "    \"\"\"\n",
    "    if j < 1:\n",
    "        changer_page = nav.find_element(By.CLASS_NAME, \"btBlue\")\n",
    "        changer_page.click()\n",
    "        sleep(5)\n",
    "    else:\n",
    "        changer_page_2 = nav.find_elements(By.CLASS_NAME, \"btBlue\")\n",
    "        retour, suivant = changer_page_2\n",
    "        suivant.click()\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def une_page(j:int, nb_articles:int):\n",
    "    \"\"\"Fonction permettant de récupérer les backups html des annonces d'une page en fonction\n",
    "    du nombre d'article voulu par page.\n",
    "    Exemple: \n",
    "    >>> une_page(1, 1)\n",
    "    >>> path + \\article_1.html\n",
    "    \"\"\"\n",
    "    for i in range(3, nb_articles+3):#47\n",
    "        sleep(3)\n",
    "        liens =  nav.find_elements(By.XPATH, \"//a[@class='jsPrdtBILA prdtBILA']\")[i]\n",
    "        liens.click()\n",
    "        sleep(6)\n",
    "        path = f\"C:/Users/Guillaume CORRE/Machine_learning/Projet/Page_{j+1}\"\n",
    "        with open(path + f\"/article_{i-2}.html\", \"w\", encoding=\"utf8\") as fichier:\n",
    "            fichier.write(nav.page_source)\n",
    "        sleep(4)\n",
    "        nav.back()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_backup(nb_articles:int, nb_page:int):\n",
    "    \"\"\"Fonction permettant de récupérer les annonces en fonction du nombre de pages et du\n",
    "    nombre d'article par page voulu. Range les backup html dans des dossiers.\n",
    "    Exemple: \n",
    "    >>> all_backup(1, 1)\n",
    "    >>> path + \\Page_1\\article_1.html\n",
    "    \"\"\"\n",
    "    code = nav.page_source\n",
    "    soupe = BS(code)\n",
    "    cookies(soupe)\n",
    "    sleep(2)\n",
    "    recherche()\n",
    "    sleep(2)\n",
    "    neuf()\n",
    "    sleep(2)\n",
    "    for j in range(0, nb_page-1):#21\n",
    "        os.mkdir(f\"Page_{j+1}\")\n",
    "        une_page(j, nb_articles-1)\n",
    "        sleep(4)\n",
    "        changer_page(j)\n",
    "        sleep(6)\n",
    "    nav.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_backup(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retour page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retour_page_1():\n",
    "    \"\"\"Fonction permettant de revenir à la première page de la recherche\n",
    "    \"\"\"\n",
    "    retour_debut = nav.find_element(By.CLASS_NAME, \"jsFirstPage\")\n",
    "    retour_debut.screenshot(\"retour_debut.png\")\n",
    "    retour_debut.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cookies_amazon(soupe:BS):\n",
    "    \"\"\"Fonction permettant de passer le problème des cookies sur Amazon\n",
    "    \"\"\"\n",
    "    elem = soupe.find(text=\"Accepter les cookies\")\n",
    "    bouton = nav.find_element(By.CLASS_NAME, \"a-button-inner\") \n",
    "    bouton.click()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_amazon():\n",
    "    \"\"\"Fonction permettant de taper l'élement de recherche voulu dans la barre de recherche\n",
    "     Cdiscount et de lancer la recherche\n",
    "    \"\"\"\n",
    "    recherche = nav.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "    #recherche.screenshot(\"recherche.png\")\n",
    "    recherche.send_keys(\"Ordinateur Portable\")\n",
    "    sleep(3)\n",
    "    recherche.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuf_amazon():\n",
    "    \"\"\"Fonction permettant de chercher l'item \"Neuf\" et de cliquer dessus.\n",
    "    Dépend du format d'affichage de la page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        neuf = nav.find_elements(By.XPATH, \"//a[@class='a-link-normal sf-filter-floatbox aok-inline-block aok-align-bottom s-no-hover s-no-underline']\")\n",
    "        indice = len(neuf)\n",
    "        neuf = nav.find_elements(By.XPATH, \"//a[@class='a-link-normal sf-filter-floatbox aok-inline-block aok-align-bottom s-no-hover s-no-underline']\")[indice - 6]\n",
    "        #neuf.screenshot(\"neuf_amazon.png\")\n",
    "        neuf.click()\n",
    "        sleep(2)\n",
    "    except:\n",
    "        neuf = nav.find_elements(By.XPATH, \"//span[@class='a-list-item']\")\n",
    "        indice = len(neuf)\n",
    "        neuf = nav.find_elements(By.XPATH, \"//span[@class='a-list-item']\")[indice - 3]\n",
    "        #neuf.screenshot(\"neuf_amazon.png\")\n",
    "        neuf.click()\n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retour/Suivant amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retour_amazon():\n",
    "    \"\"\"Fonction permettant de revenir à la page précèdente\".\n",
    "    \"\"\"\n",
    "    retour = nav.find_element(By.PARTIAL_LINK_TEXT, 'Retour aux résultats')\n",
    "    #retour.screenshot(\"retour_amazon.png\")\n",
    "    nav.get(retour.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plus simple...\n",
    "nav.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suivant_amazon():\n",
    "    \"\"\"Fonction permettant de passer à la page suivante et cherchant l'item \"Suivant\".\n",
    "    \"\"\"\n",
    "    suivant = nav.find_element(By.PARTIAL_LINK_TEXT, 'Suivant')\n",
    "    #suivant.screenshot(\"suivant_amazon.png\")\n",
    "    suivant.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def une_page_amazon(j:int, nb_articles:int):\n",
    "    \"\"\"Fonction permettant de récuperer les annonces d'une page en fonction du nombre que l'on veut\".\n",
    "    Exemple: \n",
    "    >>> une_page_amazon(1, 1)\n",
    "    >>> path + \\article_1.html\n",
    "    \"\"\"\n",
    "    for i in range(0, nb_articles-1): #41\n",
    "        sleep(3)\n",
    "        liens = nav.find_elements(By.XPATH, \"//span[@class='a-price']\")[i]\n",
    "        liens.click()\n",
    "        sleep(5)\n",
    "        path = f\"C:/Users/Guillaume CORRE/Machine_learning/Projet/Pageamazon_{j+1}\"\n",
    "        with open(path + f\"/article_{i+1}.html\", \"w\", encoding=\"utf8\") as fichier:\n",
    "            fichier.write(nav.page_source)\n",
    "        sleep(3)\n",
    "        nav.back()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction amazon finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_backup_amazon(nb_pages: int, nb_articles:int):\n",
    "    \"\"\"Fonction permettant de récuperer le nombre d'annonce sur un nombre de page défini\n",
    "    et qui va classer les backup html dans des dossiers en fonction de la page\".\n",
    "    Exemple: \n",
    "    >>> all_backup_amazon(1, 1)\n",
    "    >>> path + \\Page_1\\article_1.html\n",
    "    \"\"\"\n",
    "    nav = webdriver.Chrome()\n",
    "    nav.get(\"https://www.amazon.fr\")\n",
    "    sleep(6)\n",
    "    code = nav.page_source\n",
    "    soupe = BS(code)\n",
    "    cookies_amazon(soupe)\n",
    "    sleep(3)\n",
    "    recherche_amazon()\n",
    "    sleep(3)\n",
    "    neuf_amazon()\n",
    "    sleep(3)\n",
    "    for j in range(0, nb_pages-1): #7\n",
    "        os.mkdir(f\"Pageamazon_{j+1}\")\n",
    "        une_page_amazon(j, nb_articles-1)\n",
    "        sleep(6)\n",
    "        suivant_amazon()\n",
    "        sleep(6)\n",
    "    nav.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_backup_amazon(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'369,00€'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On clique sur le prix pour afficher la page\n",
    "recherche = nav.find_elements(By.XPATH, \"//span[@class='a-price']\")\n",
    "recherche[0].screenshot(\"recherche_amazon.png\")\n",
    "recherche[0].text\n",
    "recherche[0].click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
