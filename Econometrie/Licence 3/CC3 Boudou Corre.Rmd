---
title: "Devoir Econométrie L3 S2 Forecasting Crowds Counter"
author: "CORRE BOUDOU"
date: "`r Sys.Date()`"
output:
   rmdformats::readthedown:
     highlight: kate
     code_folding: show
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE,warning=FALSE, comment=NA, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r,echo=FALSE, message=FALSE,warning=FALSE}
library(data.table)
library(stargazer)
library(corrplot)
library(ggplot2)
library(RColorBrewer)
library(lmtest)
library(car)
library(miscTools)
library(frontier)
library(data.table)
library(skimr)
library(readxl)
library(ggplot2)
library(lmtest)
library(sandwich)
library(broom)
library(leaps)
library(orcutt)
library(strucchange)
library(lubridate)
library(questionr)
library(tidyverse)
library(forcats)
library(ggvis)
library(dplyr)
library(kableExtra)
```

# data

```{r,comment=NA}
#############################################
### Importation et création des variables ###
#############################################
data<-read.csv("CrowdCounterBDD.csv",sep=";",dec=",")
datanew<-read_xlsx("CrowdCounterNEWdataBIS.xlsx")
head(data)
```

# data and descriptive statistics

Nous n'utiliserons pas la variable Date car toutes les autres variables se forment avec Date.
```{r}
#data$apferie<-0
#data[c(1,80,102,107,110,118,161,254,260,299,304,400,432,440,440,466,492,558,566,603,693,711,723,731,771,797,863,908,913,989,1014,1019,1027,1100,1166,1173,1210,1215,1303,1316,1321,1338,1346,1375,1402,1468,1475,1512,1517,1597,1618,1623,1627,1635,1677,1704,1778,1815,1820,1893,1925,1933,1983,2009,2075,2083,2216,2227,2232,2246,2254,2287,2313,2379,2387,2424,2428,2505,2539,2533,2534,2542),10]<-1
data$apvac<-0
data[c(44,91,203,256,304,358,405,509,559,610,669,715,813,868,917,965,1012,1114,1167,1218,1272,1318,1416,1468,1519,1573,1624,1717,1770,1821,1863,1910,2023,2076,2128,2174,2221,2329,2382,2433,2487,2536),9]<-1
data$apvac=as.factor(data$apvac)
data$jour2<-data$jour
data$vacances=as.factor(data$vacances)
data$mois=as.factor(data$mois)
data$an=as.factor(data$an)
data$t=as.factor(data$t)
data$jour2=as.factor(data$jour2)
data$joursem2 <- factor(data$joursem, levels = c("Lundi", 
  "Mardi", "Mercredi", "Jeudi", "Vendredi", 
  "Samedi"))
table(data$joursem)
```
On a transformé les variables en factor et mis la variable joursem avec les jours dans le bon ordre. De plus, nous avons crée la variable apvac qui prend 1 pour les jours de rentrée et 0 sinon.

```{r}
str(data)
attach(data)
```

Premier graphique sur la variable joursem :
```{r}
ggplot(data=data)+
       aes(x=data$joursem2,y=data$nb)+
  geom_boxplot()+
  stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")


```


On retrouve une relation décroissante entre le nombre de personnes et le jour de la semaine. De plus, le samedi a un nombre de clients très faible.


Second graphique sur la variable an :
```{r}
ggplot(data=data)+
       aes(x=data$an,y=data$nb)+
  geom_boxplot()+
  stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")
```


Cela semble plutôt similaire. Toutefois, à partir de 2013, le nombre median de clients ne descend plus jamais en dessous de 430.

Troisième graphique sur la variable jour : 
```{r}
b<-mean(data$nb[data$mois==1])
c<-mean(data$nb[data$mois==2])
d<-mean(data$nb[data$mois==3])
e<-mean(data$nb[data$mois==4])
f<-mean(data$nb[data$mois==5])
g<-mean(data$nb[data$mois==6])
h<-mean(data$nb[data$mois==7])
i<-mean(data$nb[data$mois==8])
j<-mean(data$nb[data$mois==9])
k<-mean(data$nb[data$mois==10])
l<-mean(data$nb[data$mois==11])
m<-mean(data$nb[data$mois==12])
(b+c+d+e+f+g+h+i+j+k+l+m)/12

ggplot(data=data)+
       aes(x=data$jour,y=data$nb,group=jour)+
  geom_boxplot()+
  geom_hline(yintercept=480,color="red")

data$jourcarre<-data$jour^2
data$jourcarre=as.factor(data$jourcarre)

```


On reconnait une forme non linèaire qui ressemble à une fonction du second degré(Cela est surement du au fait que les personnes recoivent leurs salaires en fin et début de mois). De plus, pour tester un modèle avec variable dummy, on a calculé la moyenne générale de tous les mois donc on sépare les jours avec une moyenne plus élevée des jours avec une moyenne plus basse. On crée également la variable jour au carré que nous pourrons utiliser dans nos modèles plus tard.


Quatrième graphique sur la variable mois
```{r}
ggplot(data=data)+
       aes(x=data$mois,y=data$nb)+
  geom_boxplot()+
    stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")
```


Le mois de septembre semble clairement se démarquer des autres.


Cinquième graphique sur la variable t : 
```{r}
ggplot(data=data)+
       aes(x=data$t,y=data$nb)+
  geom_boxplot()+
  geom_hline(yintercept=350,color="red",size=2)+
  geom_hline(yintercept=450,color="green",size=2)
```


On retrouve des temporalités mais il semble également y avoir une cassure à partir de septembre 2013 où la moyenne des données semblent plus haute(droite verte) à partir de ce mois-ci.

Sixième graphique sur la variable vacances : 
```{r}
ggplot(data=data)+
       aes(x=data$vacances,y=data$nb)+
  geom_boxplot()+
  stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")
```

Petite différence, le fait d'être en vacances baisse un peu le nombre de clients.

Septième graphique sur la variable apvac : 
```{r}
ggplot(data=data)+
       aes(x=data$apvac,y=data$nb)+
  geom_boxplot()+
  stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")
```

Beaucoup plus de monde à la rentrée mais c'est logique car c'est quasiment que des lundis et les lundis ont en moyenne plus de clients.

Création de nos dummies : 
```{r}

data$joursemdummy<-ifelse(data$joursem=="Samedi",1,0)
data$joursemdummy=as.factor(data$joursemdummy)
#On sépare samedi des autres jours.
data$moisdummy<-ifelse(data$mois=="9",1,0)
data$moisdummy=as.factor(data$moisdummy)
#On sépare novembre et les autres mois.
data$jour2=as.numeric(data$jour2)
data$jourdummy<-data$jour2
data$jourdummy<-ifelse(data$jour2<=7 | data$jour2>=27,1,0)
data$jourdummy=as.factor(data$jourdummy)
#On sépare les jours au dessus et en dessous de la moyenne.
attach(data)

```

```{r}
ggplot(data=data)+
  aes(x=joursemdummy,y=nb,group=joursemdummy)+
  geom_boxplot()+
  stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")


a<-ggplot(data) + aes(y = nb,x=data$date)+ 
  geom_smooth(method="lm", se= F, size = 1, aes(colour=factor(joursemdummy))) + geom_point(aes(colour=factor(joursemdummy)))+
  ggtitle("Nombre de personne samedi ou non") +
  theme(axis.text = element_text(size=8), 
        title=element_text(size=9),
        legend.position = "bottom",
        legend.title = element_blank())
a
```
Nette différence entre samedi et les autres jours.


```{r}
ggplot(data=data)+
  aes(x=moisdummy,y=nb, group=moisdummy)+
  geom_boxplot()+
  stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")
```
Nette difference entre septembre et les autres mois.

```{r}
ggplot(data=data)+
  aes(x=jourdummy,y=nb,group=jourdummy)+
  geom_boxplot()+
  stat_summary(aes(label=..y..),fun.y = median,
               geom="text", size=4, color="darkred", vjust=-0.9)+
  stat_summary(fun.y=median, geom="point",size=3.5,color="blue", fill="blue")
  
```
Egalement une difference entre les jours au dessus de la moyenne et ceux en dessous. Nos dummies semblent donc cohérentes.


Voila pour l'analyse des données et la création de variables dummies.Nous allons maintenant passer aux tests de différents modèles.

# models and estimation

On va tout d'abord regarder notre modèle avec les dummies : 
```{r}
lmdummy<-lm(nb~joursemdummy+jourdummy+moisdummy+vacances,data=data)
summary(lmdummy)
```
Le R2 est plutôt bon et tous les coefficients sont significatifs, toutefois, pour un modèle de prédiction jour par jour, ce modèle ne semble pas vraiment adapté.

```{r}
lmdummy2c<-lm(nb~joursemdummy+jourcarre+moisdummy+vacances,data=data)
summary(lmdummy2c)
```


```{r}
data$jour<-as.factor(data$jour)
lmdummy2<-lm(nb~joursemdummy+jour+moisdummy+vacances,data=data)
summary(lmdummy2)
```
Ce modèle en mettant juste les jours en facteurs semble bon, tous les coefficients sont significatifs(sauf jour31 ce qui est logique car peu de mois ont un 31e jour) et le R2 est largement meilleur que pour le modèle lmdummy mais il ne semble pas y avoir de différence entre le fait de mettre les jours au carré ou non. De plus, les previsions de ce modèle sont bonnes.
Exemple pour le 6 juin où la vraie valeur est de 563 : 
Prevision = 993.789-430.457 environ égale à 563

Même si ce modèle est bon, il semble qu'utiliser toutes les variables en facteurs soit meilleur pour la précision de nos prédictions malgré le fait que ça ajoute beaucoup de coefficients à notre modèle.

On crée la variable dummy qui se construit à la suite de l'analyse des données pour la variable t, où il semble y avoir une différence de moyenne à partir de septembre 2013.
```{r}
data$t_rec <- fct_recode(data$t,
               "1" = "0",
               "1" = "2",
               "1" = "3",
               "1" = "4",
               "1" = "5",
               "1" = "6",
               "1" = "7",
               "1" = "8",
               "1" = "9",
               "1" = "10",
               "1" = "11",
               "1" = "12",
               "1" = "13",
               "1" = "14",
               "1" = "15",
               "1" = "16",
               "1" = "17",
               "1" = "18",
               "1" = "19",
               "1" = "20",
               "1" = "21",
               "1" = "22",
               "1" = "23",
               "1" = "24",
               "1" = "25",
               "1" = "26",
               "1" = "27",
               "1" = "28",
               "1" = "29",
               "1" = "30",
               "1" = "31",
               "1" = "32",
               "1" = "33",
               "1" = "34",
               "1" = "35",
               "1" = "36",
               "1" = "37",
               "1" = "38",
               "1" = "39",
               "1" = "40",
               "1" = "41",
               "1" = "42",
               "1" = "43",
               "1" = "44",
               "0" = "45",
               "0" = "46",
               "0" = "47",
               "0" = "48",
               "0" = "49",
               "0" = "50",
               "0" = "51",
               "0" = "52",
               "0" = "53",
               "0" = "54",
               "0" = "55",
               "0" = "56",
               "0" = "57",
               "0" = "58",
               "0" = "59",
               "0" = "60",
               "0" = "61",
               "0" = "62",
               "0" = "63",
               "0" = "64",
               "0" = "65",
               "0" = "66",
               "0" = "67",
               "0" = "68",
               "0" = "69",
               "0" = "70",
               "0" = "71",
               "0" = "72",
               "0" = "73",
               "0" = "74",
               "0" = "75",
               "0" = "76",
               "0" = "77",
               "0" = "78",
               "0" = "79",
               "0" = "80",
               "0" = "81",
               "0" = "82",
               "0" = "83",
               "0" = "84",
               "0" = "85",
               "0" = "86",
               "0" = "87",
               "0" = "88",
               "0" = "89",
               "0" = "90",
               "0" = "91",
               "0" = "92",
               "0" = "93",
               "0" = "94",
               "0" = "95",
               "0" = "96",
               "0" = "97",
               "0" = "98",
               "0" = "99")
data$t_rec=as.factor(data$t_rec)

```

```{r}
data$jour <- factor(data$jour,levels=c("2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","1"))
data$joursem<-factor(data$joursem, levels =c("Samedi","Lundi", 
  "Mardi", "Mercredi", "Jeudi", "Vendredi"))
                     
lm1<-lm(nb~data$jour+mois+joursem+an+vacances+data$t_rec+apvac,data=data)
summary(lm1)
```
Essayons avec la variable nb au log
```{r}
data$lognb<-log(data$nb)
attach(data)
lm1<-lm(lognb~jour+mois+joursem+an+vacances+t_rec+apvac,data=data)
summary(lm1)

```
On a largement amélioré le R2 et rendu plus de coefficients significatifs.On voit que la variable t_rec qui sépare la cassure vu grâce à l'analyse des données est significative, il faut tester si cela rend le modèle instable ou non avec un test de CHOW.

```{r}
data1<-data[data$t_rec==0,]
data2<-data[data$t_rec==1,]

lm1bis<-lm(lognb~data2$jour+data2$mois+data2$joursem+data2$vacances+data2$an+data2$apvac,data=data2)
summary(lm1bis)
lm1ter<-lm(lognb~jour+mois+joursem+vacances+an+apvac,data=data1)


SCR1=sum(lm1ter$residuals^2)
SCR2=sum(lm1bis$residuals^2)
SCRtot=sum(lm1$residuals^2)
(CHOWF=((SCRtot-(SCR1+SCR2))/(SCR1+SCR2))*(2550-96)/(48))

qf(.95, df1=48, df2=2454)
pf(CHOWF,df1=48, df2=2454,lower.tail = FALSE)

```
Il semble donc y avoir une différence car 2.88 > 1.36.En temps normal, nous aurions grader la régression contenant seulement les observations réalisées après la cassure structurelle mais nous allons garder la variable t_rec et toutes les données car cela enleverait trop de données et, pour des previsions calendaires, il semble que de garder toutes les spécificités des données soit important.


Testons maintenant un modèle avec interactions : 

```{r}
lm2<-lm(lognb~jour*mois+joursem+mois+vacances+an+t_rec,data=data)
summary(lm2)
```
Cela améliore beaucoup le R2, mais nous avons également beaucoup de coefficients non significatifs et n'arrivons pas à les enlever.De plus, pour les prévisions, nous avions des problèmes dû au grand nombre de coefficients. Nous avons donc décider de garder un modèle sans interaction pour faciliter les prévisions.


Faisons le diagnostic de notre modèle(lm1) : 
```{r}
lm1<-lm(lognb~jour+mois+joursem+an+vacances+t_rec+apvac,data=data)
summary(lm1)
```

```{r}
fitted=predict(lm1, data)
plot(data$lognb~fitted,main="Preticted vs actual",xlab="valeurs predites",ylab="valeurs actuelles")
abline(a=0, b=1, col="red")
```
Le modèle est correct.

```{r}
hist(lm1$residuals, freq=FALSE,col="darkred",main="Distribution des résidus",xlab="Résidus",ylab="Densité",xlim=c(-2,2),ylim=c(0,1.2))
lines(density(lm1$residuals),col="blue")
```
La distribution des résidus semble bien suivre la distribution d'une loi normale, ils sont bien centrés sur 0.

```{r}
qqPlot(lm1, id.n=2)#2459,2461
```
Ce graphique permet de comparer les résidus avec la distribution normale.Les points suivent parfaitement la ligne donc le terme d'erreur est distribué normalement. Le graphique nous donne deux observations avec de grands résidus standardisés, ce sont les observations 2459 et 2461.

```{r}
residualPlots(lm1)
```
Toutes les médianes des résidus semblent être centrées sur 0, ce qui est positif. Toutefois, le dernier grahique montre qu'il reste une forme non linéaire, même si celle si n'est pas trop forte.

```{r}
head(sort(hatvalues(lm1),decreasing = T))
```
On regarde toutes les observations avec les plus grands résidus standardisés.

```{r}
influencePlot(lm1)
data<-data[-c(2459,2461,2550,2504,1716,1516,2326,2453,2300),]
```
Gràce à ce graphique et aux observations précèdentes sur les résidus, on a décidé d'enlever les 10 observations avec les plus grands résidus standardisés.

```{r}
lm1<-lm(lognb~jour+mois+joursem+an+vacances+t_rec+apvac,data=data)
summary(lm1)
```
Cela nous a donc amélioré le R2, ce qui n'est pas une surprise.

Nous allons maintenant regarder s'il y a de l'autocorrélation et la corriger si nécessaire.
```{r}
dwtest(lm1)
lm1<-cochrane.orcutt(lm1,convergence=8,max.iter=100)
dwtest(lm1)
```
On passe donc d'un coefficient de DW de 0.92 à 2.16. 

Maintenant, nous allons corriger l'hétéroscédasticité de notre modèle.
```{r}
data$resi <- lm1$residuals
attach(data)

varfunc.ols <- lm(log(resi^2)~jour+mois+joursem+an+vacances+t_rec+apvac,data=data)

data$varfunc <- exp(varfunc.ols$fitted.values)
lm1cor <- lm(lognb~jour+mois+joursem+an+vacances+t_rec+apvac, weights = 1/sqrt(varfunc), data = data)
summary(lm1cor)
bptest(lm1cor)

```
Grâce à cette correction, le R2 est passé de 0.85 à 0.87 et l'erreur des résidus semble avoir diminué.
```{r}
valeurconstante<-exp(6.143289+((0.5727/(2541-57))/2))
valeurconstante
```
Notre date de référence dans le modèle est le 2 janvier 2010 et le modèle nous donne une prévision de 465 clients pour une valeur réelle de 462 clients.

# Forecasting

```{r}
datanew$logvalreelles<-log(datanew$"Valeurs réelles")
#mean(`Valeurs réelles`)

```

```{r}
datanew<-datanew %>% arrange(Date) %>%  mutate(an=year(Date),
                                      mois=month(Date),
                                      jour =day(Date))


datanew$joursem<-c("Vendredi","Samedi","Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Lundi","Mardi","Mercredi","Jeudi","Vendredi","Lundi","Mardi","Mercredi","Jeudi")
datanew$vacances<-1
datanew$vacances[1:31]<-0
datanew$t_rec<-0
datanew$apvac<-0
#datanew$apferie<-0
#datanew[c(38),10]<-1

an=c(datanew$an)
jour=c(datanew$jour)
joursem=c(datanew$joursem)
mois=c(datanew$mois)
vacances=c(datanew$vacances)
t_rec=c(datanew$t_rec)
apvac=c(datanew$apvac)
#apferie=c(datanew$apferie)

data3<-data.frame(cbind(jour,joursem,mois,vacances,an,t_rec,apvac))

predict<-predict(lm1cor,data3,level=0.95,interval = "confidence")
colnames(predict)<-c("Valeurs prédites","Borne inf","Borne sup")
valeurscorrigees<-((0.5727/(2541-57))/2)
predict<-exp(predict+valeurscorrigees)
predict %>% kable(caption="Résultat de nos prévisions sur les nouvelles données")


predict2<-predict(lm1ter,data3,level=0.95,interval = "confidence")
colnames(predict2)<-c("fit2","lwr2","upr2")
predict2<-exp(predict2+valeurscorrigees)


datanew<-cbind(datanew,predict,predict2)



attach(datanew)
```


```{r}
datanew %>% ggvis(~datanew$Date,~datanew$`Valeurs réelles`)%>%
  layer_paths() %>% 
  layer_paths(~datanew$Date,~datanew$`Valeurs prédites`, stroke:="red")
```
Sur ce graphique, on peut voir notre prédiction(courbe rouge) et les vraies valeurs (courbe noire). 

```{r}
datanew %>% ggvis(~datanew$Date,~datanew$`Valeurs réelles`)%>%
  layer_paths() %>% 
  layer_paths(~datanew$Date,~datanew$`Valeurs prédites`, stroke:="red") %>% 
  layer_paths(~datanew$Date,~datanew$fit2, stroke:="blue")

```
Sur ce graphique, on a rajouté les previsions pour le modèle lm1ter en prenant en compte que les données récentes. Les prévisions semblent très proches, calculons le R2 associé à chaque prévision.

```{r}
datanew$difference<-datanew$`Valeurs prédites`-datanew$`Valeurs réelles`
datanew$differencecarree<-datanew$difference^2
SCR=sum(datanew$differencecarree)
datanew$sct<-datanew$`Valeurs réelles`-mean(datanew$`Valeurs réelles`)
datanew$sctcarre<-datanew$sct^2
SCT=round(sum(datanew$sctcarre),2)
SCE=round(sum(datanew$sctcarre)-sum(datanew$differencecarree),2)
R2=round(1-(SCR/SCT),4)
R2

```
Le R2 associé à notre prédiction est de 0.9489.

```{r}
datanew$difference2<-datanew$fit2-datanew$`Valeurs réelles`
datanew$differencecarree2<-datanew$difference2^2
SCR2=sum(datanew$differencecarree2)
datanew$sct2<-datanew$`Valeurs réelles`-mean(datanew$`Valeurs réelles`)
datanew$sctcarre2<-datanew$sct2^2
SCT2=round(sum(datanew$sctcarre2),2)
SCE2=round(sum(datanew$sctcarre2)-sum(datanew$differencecarree2,2))
R22=round(1-(SCR2/SCT2),4)

```



```{r}
a<-c(mean(datanew$`Valeurs prédites`),mean(datanew$fit2))
b<-c(SCR,SCR2)
c<-c(SCT,SCT2)
d<-c(SCE,SCE2)
e<-c(R2,R22)


matrice<-t(cbind(a,b,c,d,e))
rownames(matrice)<-c("Moyenne de clients","SCR","SCT","SCE","R2")
colnames(matrice)<-c("Modèle lm1cor","Modèle lm1ter")
matrice %>% kable(caption="Difference modèle complet et modèle récent")
```






