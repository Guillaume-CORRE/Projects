---
title: "Devoir Econométrie L3 S2 Hétéroscédasticité"
author: "CORRE FETEIRA DHORBAIT"
date: "`r Sys.Date()`"
output:
   rmdformats::readthedown:
     highlight: kate
     #code_folding: show
   prettydoc::html_pretty:
    theme: cayman
    highlight: github

---


```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.height = 4, fig.width = 8)
```

```{r package}
library(stargazer)
library(psych)
library(lmtest)
library(ggplot2)
library(broom)
library(sandwich)
library(leaps)
library(car)
library(tseries)
library(kableExtra)
library(gridExtra)
```


# Question 1

```{r import}
setwd("D:/Econometrie/Licence 3/Semestre 2/Devoir 1")
food <- read.csv(file='BudgetFood.csv',header=TRUE,sep=",",dec=".")
```

Tout d'abord, nous ne pensons pas que les valeurs nulles pour wfood soient intéressantes dans nos différents modèles. En effet, on veut voir un lien avec la part du salaire allouée à l'alimentation, or si la part est de 0%, comment l'interpréter ? La personne produit-elle elle même ses produits ? De ce point de vue, l'argent depensé pour produire ne doit-il pas être comptabilisé ? La personne n'a peut-être pas de salaire, ce qui signifierait que l'intérêt de l'observer est très faible. Nous avons donc décidé de supprimer ces données. On enlève également la valeur manquante car le sexe de l'individu de référence n'a pas été renseigné et on crée la variable dummy sex avec comme valeur de référence les hommes.

```{r NA, include=FALSE}
table(is.na(food$sex))
food<-na.omit(food)
food<-food[!food$wfood==0,]
food<-droplevels(food)
food$sex<-as.integer(food$sex)
food$sex[food$sex=="1"]<-0
food$sex[food$sex=="2"]<-1
# donc homme comme reference car = 0
attach(food)
```

Comme 1er modèle, nous testons le modèle simple, contenant toutes les variables sans les modifier : <br>
$wfood_i=\alpha+\beta_1*totexp_i+\beta_2*age_i+\beta_3*size_i + \beta_4*town_i + \beta_5*sex_i + \epsilon_i$
```{r modele1simple}
lm1<-lm(wfood~totexp+age+size+town+sex)
summary(lm1)
```
Tous les coefficients sont significatifs sauf sex et la statistique de Fisher est de 2648 donc on rejette H0, l'hypothèse des coefficients nuls. On a ici un $R^2$ de 0.3565.
```{r}
food$agedummy<-food$age
food$agedummy[food$agedummy<=30]<-0
food$agedummy[food$agedummy>=30]<-1
attach(food)

p_agedummy <- ggplot(food) + aes(y = wfood, x = age) + 
  geom_point(aes(colour=factor(agedummy))) + 
  geom_smooth(method="lm", se= F, size = 1, aes(colour=factor(agedummy))) + 
  ggtitle("Salaire en fonction de l'age") +
  theme(axis.text = element_text(size=8), 
        title=element_text(size=9),
        legend.position = "bottom",
        legend.title = element_blank())
p_agedummy
```
<br> On remarque à travers ce graphique qu'il semblerait y avoir une relation différente entre wfood et les personnes de moins de 30 ans (relation décroissante, on prendra cette catégorie comme référence) et wfood et les personnes de plus de 30 ans(relation croissante). Cela est sûrement dû à l'âge moyen auquel on a un enfant et il s'agit également de la rupture entre les personnes débutants dans la vie active et les personnes un peu plus avancées et dans des situations souvent plus confortables. <br>

On crée les dummies towndummy avec les petites et moyennes villes ($<3$) comme référence et la variable catégorielle size avec les catégories de 1, 2, 3, 4 et 5 ou plus de 5 personnes :
```{r dummies}
str(food)
food$towndummy<-food$town
food$towndummy[food$towndummy<=3]<-0
food$towndummy[food$towndummy>=4]<-1
# donc petites et moyennes villes comme reference

ggplot(food, aes(x=size))+
   geom_bar(stat="count", width=0.7, fill="darkred")+
   theme_minimal()+coord_flip()+
   ggtitle("Nombre de familles en fonction du nombre de personnes dans le foyer")+
   labs(x="Nombre de personnes dans le foyer",y="Nombre de familles")
#Ici 5 et plus represente une part plus petite, nous allons donc les combiner
food$sizedummy<-food$size
food$sizedummy[food$sizedummy==1]<-1
food$sizedummy[food$sizedummy==2]<-2
food$sizedummy[food$sizedummy==3]<-3
food$sizedummy[food$sizedummy==4]<-4
food$sizedummy[food$sizedummy>=5]<-5
food$sizedummy=as.factor(food$sizedummy)
attach(food)
kable(table(food$sizedummy)/23911, caption="Proportion des tailles des ménages") %>%
  kable_styling(full_width=FALSE) %>% row_spec(0, col="red") %>% column_spec(1, bold=TRUE)
```

Nous décidons donc de comparer les petites et moyennes villes aux plus grandes. Il serait donc intérressant de séparer ces deux catégories. En effet, on sait que les salaires sont plus élevés dans les grandes villes mais les prix sont également plus élevés. Nous voulons donc voir si la part du revenu allouée à l'alimentation entre moyennes et grandes villes va être significativement différente de 0 ou pas. Autrement dit, est-ce que l'augmentation des salaires est plus élevée que l'augmentation des prix des denrées alimentaires entre les petites/moyennes et grandes villes ? <br>
En ce qui concerne la taille des familles, l'étude est simple, nous voulons savoir si la part allouée à la nourriture augmente avec le nombre de personnes. De plus, d'après notre graphique et tableau, il semblerait que seulement 70% des familles sont composées de 4 personnes ou moins. Il y aurait donc 30% des familles composées de 5 personnes ou plus, ce qui représente une proportion non négligeable. <br>



Pour ce 2ème modèle, on décide de mettre les variables age et town en dummies et la variable size en catégorie, comme expliqué ci-dessus : <br>
$wfood_i=\alpha+\beta_1*totexp_i+\beta_2*agedummy_i+\beta_3*sizedummy_i + \beta_4*towndummy_i + \beta_5*sex_i + \epsilon_i$
```{r modele2dummies}
lm2<-lm(wfood~totexp+agedummy+sizedummy+towndummy+sex)
summary(lm2)
anova(lm1,lm2)
stargazer(lm1, lm2, type="text")
```
Il semblerait que le modèle simple soit plus précis que le modèle avec les variables dummies. En effet, le $R^2$ du modèle est un peu plus élevé. De plus, on observe que les écarts-types estimés des variables town et age sont plus faibles quand elles ne sont pas mises en dummies, malgré que cela ne soit pas significatif (test ANOVA nous dit que les variances des 2 modèles ne sont pas significativement différentes). De plus, il semblerait que l'ajout des dummies age, town et size a diminué la significativité de la variable sex. Enfin, les erreurs des résidus standardisés ont légérement augmenté pour le modèle 2 par rapport au modèle 1. <br>


Nous testons, le modèle 3 avec la variable agecarre, en prenant l'âge au carré : <br>
$wfood_i=\alpha+\beta_1*totexp_i+\beta_2*age_i^2+\beta_3*size_i + \beta_4*town_i +\beta_5*sex_i+ \epsilon_i$
```{r modele2carre}
food$agecarre<-(food$age)^2
attach(food)
lm3<- lm(wfood~totexp+agecarre+age+size+town+sex)
summary(lm3)
stargazer(lm1, lm3, type="text")
```
Tous les coefficients sont significatifs sauf la variable agecarre qui semblerait ici inutile donc on a pas d'intérêt à mettre la variable age au carré. <br>
```{r}
recherche<-regsubsets(wfood~totexp+agedummy+sizedummy+towndummy+sex,int=T,nbest=1,nvmax=9,
                      method="exhaustive",really.big=T,data=food)
plot(recherche,scale="r2")
```
<br> On remarque que notre modèle peut avoir le même $R^2$ en enlevant la variable sex, comme vu précédemment. Elle n'était donc pas vraiment significative. De plus, cela permet de rendre plus stable la régression et de nous faire gagner un degré de liberté. <br>
En conclusion, le modèle simple et le modèle avec les variables modifiées en dummies sont quasiment similaires. Il semble donc plus intérressant de garder un modèle où l'on peut faire des interprétations sur plusieurs catégories pour chaque variable. Toutefois, nous garderons les deux modèles pour faire des comparaisons dans les questions qui suivent.





# Question 2

On regarde la matrice variance-covariance :
```{r matricecov}
food2<-food[,2:6]
variab=subset(food2)
pairs.panels(variab)
```
<br> On remarque qu'il semblerait y avoir des relations entre la variable totexp et les variables age et size. Nous allons essayer de les mettre en relation pour voir si notre modèle s'améliore ou pas : <br>
$wfood_i=\alpha+\beta_1*totexp_i+\beta_2*age_i+\beta_3*size_i + \beta_4*town_i + \beta_5*(totexp_i*age_i) + \beta_6*(totexp_i*size_i) + \epsilon_i$
```{r modele4interaction}
lm4<-lm(wfood~totexp*age+totexp*size+town)
summary(lm4)
```
Par rapport au modèle 1, nous avons amélioré le $R^2$ avec ce modèle 4. On rejette toujours l'hypothèse H0 des coefficients nuls. De plus, on remarque que nos coefficients sont toujours tous significatifs. Il semblerait donc que l'on peut mettre en relation les dépenses totales avec l'âge et la taille du ménage. <br>


On essaye maintenant un modèle en mettant en interaction la variable totexp avec les variables agedummy et sizedummy et en prenant la variable town en dummy : <br>
$wfood_i=\alpha+\beta_1*totexp_i+\beta_2*sizedummy_i + \beta_3*towndummy_i + \beta_4*(totexp_i*agedummy_i) + \beta_5*(totexp_i*sizedummy_i) + \epsilon_i$
```{r modele5interaction}
lm5<-lm(wfood~totexp*agedummy+totexp*sizedummy+towndummy)
summary(lm5)
```
Par rapport au modèle 2, nous avons amélioré le $R^2$ avec ce modèle 5. On rejette toujours l'hypothèse H0 des coefficients nuls. De plus, on remarque que nos coefficients sont tous significatifs sauf sizedummy3 et sizedummy4, qui représentent les familles de 3 et 4 personnes. Il semblerait donc que l'on peut mettre en relation les dépenses totales et nos variables catégorielles pour l'âge, la taille du ménage et la taille de la ville. <br>
```{r test4et5}
anova(lm4,lm5)
```
Avec le test ANOVA, on en conclut que les variances ne sont pas significativement différentes. Enfin, les critères AIC et BIC nous indiquent que le modèle 4 semblerait légèrement meilleur que le modèle 5 :
```{r test4et5suite}
reg<-cbind(c(AIC(lm4),AIC(lm5)),c(BIC(lm4),BIC(lm5)))
colnames(reg)<-c("AIC", "BIC")
rownames(reg)<-c("Modèle 4", "Modèle 5")
kable(reg, caption="") %>% kable_styling(full_width=FALSE) %>% column_spec(1, bold=T) %>% 
  row_spec(0,bold=T, col="red")
```
De plus, on remarquera que pour chaque modèle, les erreurs des résidus standardisés ont faiblement diminué et le $R^2$ a augmenté. Encore une fois, les deux modèles semblent similaires.






# Question 3


```{r}
residualPlots(lm4)
```
Le graphique en haut à gauche nous montre que les residus ont une forme non linéaire. Passer au log la variable totexp, va certainement permettre de corriger la non linéarité des résidus.
```{r creationlog}
food$logtotexp<-log(food$totexp)
#food$logage<-log(food$age)
attach(food)
```
On décide de créer le modèle simple mais en prenant cette fois-ci les logarithmes de la variable totexp : <br>
<font size=2> $wfood_i=\alpha+\beta_1*logtotexp_i+\beta_2*age_i+\beta_3*size_i + \beta_4*town_i + \beta_5*(logtotexp_i*size_i) + \epsilon_i$ </font>
```{r}
lm6<-lm(wfood~logtotexp+age+logtotexp*size+town)
summary(lm6)
residualPlots(lm6)
```
On a donc corrigé la non linéarité de la variable totexp. On observe une nette augmentation du $R^2$ qui passe à 0.411. De plus, les coefficients sont toujours tous significatifs et on remarque qu'il est plus facile de lire les estimations des coefficients comme nous n'avons plus de variables très très petites. La statistique de Fisher est toujours très élevée donc on rejette encore l'hypothèse H0 qui dit que les coefficients sont nuls. <br>

On teste maintenant un modèle pour expliquer les dépenses alimentaires selon les variables dépenses totales, agedummy, sizedummy et towndummy : <br>
<font size=2> $wfood_i=\alpha+\beta_1*logtotexp_i+\beta_2*agedummy_i+\beta_3*sizedummy_i+\beta_4*towndummy_i +\beta_5*(logtotexp_i*agedummy_i)+\beta_6*(logtotexp_i*sizedummy_i)+\epsilon_i$ </font>
```{r}
lm7<-lm(wfood~logtotexp+logtotexp*agedummy+logtotexp*sizedummy+towndummy)
summary(lm7)
```
Tous les coefficients sont toujours significatifs. On rejette encore l'hypothèse H0 de nullité des coefficients. Le $R^2$ a augmenté par rapport au modèle sans la variable totexp au logarithme et les erreurs des résidus standardisés ont diminué. Le modèle semble donc s'être amélioré. <br>

Nous allons maintenant nous intéresser à un modèle qui nous permettra de calculer l'élasticité revenu des biens alimentaires. En effet, la part du revenu allouée à l'alimentation est en pourcentage. Nous multiplions donc la variable totexp avec la variable wfood afin d'avoir les dépenses liées à l'alimentation :
```{r}
food$logfood=wfood*totexp
food$logfood=log(food$logfood)
attach(food)
```
$logfood_i=\alpha+\beta_1*logtotexp_i+\beta_2*agedummy_i+\beta_3*sizedummy_i + \beta_4*towndummy_i + \epsilon_i$
```{r}
lm8<-lm(logfood~logtotexp+agedummy+sizedummy+towndummy)
summary(lm8)
```
On remarque que tous les coefficients sont différents de 0 et significatifs. Le coefficient $\beta_1$ s'interprète comme l'élasticité de la demande par rapport au revenu. On observe ici que le coefficient est de 0.49, donc il s'agit d'un bien normal et même d'un bien de première nécessité. La demande des biens alimentaires est inélastique. On obtient donc que si le revenu augmente de 1%, la demande pour les biens alimentaires va donc augmenter de 0.49%. <br>

On remarque pour chaque régression que par rapport aux questions 1 et 2, un modèle niveau-log (modèle 7) permet une amélioration du $R^2$ ainsi qu'une diminution des résidus standardisés. Les modèles semblent donc meilleurs en niveau-log que en niveau-niveau (modèles 1, 2, 3, 4 et 5). <br>
En ce qui concerne le modèle log-log (modèle 8), nous obtenons un $R^2$ plus élevé que les modèles précèdents, mais ceci s'explique par le fait que l'on pourrait réécrire $totexp = depenseA + depenseNA$, avec le total des dépenses qui sont égales aux dépenses alimentaires additionné aux dépenses non alimentaires, c'est-à-dire qu'ici la variable totexp serait donc en partie endogène. Cependant, on remarque également une forte hausse des erreurs des résidus standardisés, le modèle est donc moins précis.





# Question 4

Nous allons maintenant vérifier si il y a de l'hétéroscédasticité dans nos modèles ou pas. On cherche à corriger l'hétéroscédasticité du modèle simple sans la variable sex (modèle 1), donc pour cela on commence par regarder si les résidus suivent une loi normale en faisant le test de Jarque Bera :
```{r}
lm1<-lm(wfood~totexp+age+size+town)
food$resi2 <- lm1$residuals
hist(food$resi2, freq=FALSE, col="darkred")
attach(food)
jarque.bera.test(lm1$residuals)
```
Le test de Jarque Bera nous indique donc que les résidus ne suivent pas une loi normale.
```{r}
ggplot(data = food, aes(y = resi2, x =totexp)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi2, x =age)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi2, x =size)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi2, x =town)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
```
D'après les graphiques ci-dessus, il semblerait qu'il y ait de l'hétéroscédasticité. On fait le test de Koenker, qui est un test de Breusch-Pagan quand il n'y a pas normalité des résidus, pour regarder si il n'y aurait pas de l'hétéroscédasticité :
```{r}
var.func2 <- lm(resi2^2 ~ totexp+age+size+town, data = food)
summary(var.func2)
kable(qchisq(.95, df = 4), caption="Quantile à 5% du Khi-Deux pour 4 DDL") %>%
  kable_styling(full_width=FALSE) %>% row_spec(0, col="red")
bptest(lm1, studentize = TRUE)
```
Il semblerait donc qu'il y ait de l'hétéroscédasticité dans le modèle simple car la p-value du test est strictement inférieure à 0.001 . On le confirme avec le test de White :
```{r}
ressq2=food$resi2^2
modres2 <- lm(ressq2~totexp+age+size+town, data=food)
summary(modres2)
gmodres2 <- glance(modres2)
Rsq2 <- gmodres2$r.squared
S2 <- gmodres2$df #Number of Betas in model
N2<-nrow(food)
chisq2 <- N2*Rsq2
pval2 <- 1-pchisq(chisq2, S2-1)
kable(pval2, caption="p-value du modèle 1") %>%
  kable_styling(full_width=FALSE) %>% row_spec(0, col="red")
```
La p-value étant très très proche de 0, le test de White nous confirme que l'on a de l'hétéroscédasticité. Donc, nous la corrigeons :
```{r}
coeftest(lm1, vcov = vcovHC(lm1, "HC1"))
varfunc.ols2 <- lm(log(resi2^2) ~ log(totexp)+log(age)+log(size)+log(town),data = food)
food$varfunc2 <- exp(varfunc.ols2$fitted.values)
```

```{r}
lm1_cor<-lm(wfood~totexp+age+size+town, weights=1/sqrt(varfunc2), data=food)
stargazer(lm1,lm1_cor, type="text")
```
Après avoir corrigé les problèmes de variance des résidus non constants pour le modèle 1, on remarque que les estimations et les écarts-types estimés des variables n'ont pas été fortement modifié. Le $R^2$ a quant à lui été amélioré pour passer de 0.356 à 0.361. Cependant, on remarquera une forte augmentation des erreurs des résidus standardisés qui sont passées de 0.132 à 0.499. Le modèle n'est donc plus un BLUE (Best Linear Unbiased Estimator), puisqu'il est maintenant biaisé. <br>
Nous allons donc maintenant interpréter le modèle corrigé car il est biaisé mais il n'a pas de problèmes d'hétéroscédasticité vu qu'il possède des écarts-types robustes. Ces résultats ne sont donc pas très précis, mais nous ne remarquons pas de grands écarts entre le modèle hétéroscédastique et le modèle corrigé. On observe qu'une augmentation de 1000€ des dépenses entraîne une diminution de 0.00013 de la part du revenu allouée aux dépenses alimentaires. On remarque également qu'une augmentation d'une année de l'âge de l'individu de référence du ménage entraine une augmentation de 0.002 de la part du revenu allouée à l'alimentation. De plus, une augmentation d'une personne dans un ménage, augmente de 0.021 la part du revenu allouée à l'alimentation. Enfin, une augmentation de la taille de la ville de 1 diminue la part du revenu allouée à l'alimentation de 0.017. <br>
En conclusion, il semblerait que la part du revenu allouée aux dépenses alimentaires diminue seulement si la ville augmente en taille. Autrement dit, plus on habite dans une grande ville plus notre part du revenu allouée à l'alimentation sera faible ce qui pourrait s'expliquer par le fait que l'augmentation des prix des denrées alimentaires en grandes villes serait plus rigide que l'augmentation des salaires. On remarque également qu'une augmentation des dépenses entraine une baisse de la part du revenu allouée aux dépenses alimentaires, cependant, cet effet est très très faible puisqu'il faudrait une augmentation de 1 million d'euros pour diminuer de 0.13 la part du revenu allouée à l'alimentation, ce qui représente beaucoup de dépenses pour une faible baisse de la part du revenu allouée à l'alimentation. <br>




On étudie maintenant le modèle 6 et comme pour le modèle précédent, on va vérifier que les résidus suivent une loi normale :
```{r normalite}
food$resi <- lm6$residuals
hist(food$resi, freq=FALSE, col="darkred")
attach(food)
jarque.bera.test(lm6$residuals)
```
D'après le test de Jarque Bera, les résidus ne suivent pas une loi normale.

```{r residu}
ggplot(data = food, aes(y = resi, x =logtotexp)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi, x =age)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi, x =size)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi, x =town)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi, x =logtotexp*size)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
```
Après avoir regardé les résidus de chacunes des variables du modèle, on s'aperçoit qu'il semblerait y avoir des problèmes d'hétéroscédasticité. On le vérifie avec le test de Koenker, qui est un test de Breusch-Pagan quand il n'y a pas normalité des résidus :

```{r testpagan}
var.func <- lm(resi^2 ~ logtotexp+age+logtotexp*size+town, data = food)
summary(var.func)
kable(qchisq(.95, df = 5), caption="Quantile à 5% du Khi-Deux pour 5 DDL") %>%
  kable_styling(full_width=FALSE) %>% row_spec(0, col="red")
bptest(lm6, studentize = TRUE)
```
On a très clairement des problèmes d'hétéroscédasticité, c'est-à-dire que la variance des résidus n'est pas constante. On le vérifie avec le test de White :

```{r testwhite}
ressq=food$resi^2
modres <- lm(ressq~logtotexp+age+logtotexp*size+town, data=food)
summary(modres)
gmodres <- glance(modres)
Rsq <- gmodres$r.squared
S <- gmodres$df #Number of Betas in model
N<-nrow(food)
chisq <- N*Rsq
pval <- 1-pchisq(chisq, S-1)
kable(pval, caption="p-value du modèle 6") %>%
  kable_styling(full_width=FALSE) %>% row_spec(0, col="red")
```
Le test de White confirme que notre modèle a un problème d'hétéroscédasticité car la p-value est très très proche de 0. On corrige donc l'hétéroscédasticité :

```{r corrigeheteroscedastcite}
coeftest(lm6, vcov = vcovHC(lm6, "HC1"))
varfunc.ols <- lm(log(resi^2) ~ log(logtotexp)+log(age)+log(logtotexp*size)+log(town),data = food)
food$varfunc <- exp(varfunc.ols$fitted.values)
```

```{r}
lm6_cor<-lm(wfood~logtotexp+age+logtotexp*size+town, weights=1/sqrt(varfunc), data=food)
stargazer(lm6,lm6_cor, type="text")
```
On notera que les coefficients des différentes variables explicatives et de notre constante sont modifiés. Les écarts-types estimés des variables ne semblent pas avoir beaucoup été modifiés sauf pour la constante qui a vu son écart-type estimé passer de 0.034 à 0.0036 et l'écart-type estimé de la variable logtotexp a également augmenté de 0.002 à 0.003. Enfin, on remarquera que le $R^2$ a augmenté à 0.426. Cependant, on voit une très nette augmentation des erreurs des résidus standardisés, qui passent à 0.488, ce qui est très élevé. Le modèle n'est donc plus un BLUE (Best Linear Unbiased Estimator) car il est maintenant biaisé. <br>
Nous allons donc maintenant interpréter le modèle corrigé car il est biaisé mais il n'a pas de problèmes d'hétéroscédasticité vu qu'il possède des écarts-types robustes. Ces résultats ne sont donc pas très précis, mais nous ne remarquons pas de grands écarts entre le modèle hétéroscédastique et le modèle corrigé. On observe qu'une augmentation de 1% des dépenses, entraine une diminution de 0.113% de la part du revenu allouée à l'alimentation. De plus, une augmentation d'une année de la personne de référence entraîne une augmentation de 0.002 de la part du revenu allouée à l'alimentation. Il semblerait également qu'une augmentation d'une personne dans la taille du ménage entraine une augmentation de 0.18 de la part du revenu allouée à l'alimentation. On observe qu'une augmentation de la taille de la ville de 1 diminue de 0.012 la part du revenu allouée à l'alimentation. Enfin, une augmentation d'une personne dans le ménage entraine une baisse de 0.011 sur le logarithme des dépenses totales et donc l'effet marginal du logarithme entraine une baisse de 0.123% (<font size=2>$(-0.113-0.011)*log(1.01)$</font>) de la part du revenu allouée à l'alimentation.<br>
En conclusion, il semblerait que seulement l'âge et la taille du ménage augmente la part du revenu allouée à l'alimentation. En effet, cela peut sembler cohérent puisque plus le ménage est grand plus il va falloir dépenser en alimentation pour nourir tout le monde (ce n'est pas le même budget de nourir 4 et 8 personnes) alors que le revenu des personnes n'a pas d'impact sur le nombre de personnes nécessitant de se nourir, si l'on part du principe que la majorité des données sont des familles avec 2 parents et plusieurs enfants. De plus, on peut imaginer que la part du revenu allouée à l'alimentation est directement liée avec l'âge puisque plus l'on vieillit plus notre salaire augmente, car nous prenons de l'expérience sur le marché du travail, on aurait donc des revenus qui augmentent pour une augmentation des dépenses alimentaires relativement plus faible puisque plus on est âgé, moins on a de chances d'avoir nos enfants encore présent dans le ménage et on a tendance à peut-être moins manger. <br>




Enfin, pour finir, on regarde si notre modèle 7 comporte de l'hétéroscédasticité. Pour commencer, on regarde si il y a normalité des résidus :
```{r residu3}
food$resi3 <- lm7$residuals
attach(food)
hist(food$resi3, freq=FALSE, xlim=c(-1,1),col="darkred")
jarque.bera.test(lm7$residuals)
```
Avec le test de Jarque Bera, on peut en conclure que les résidus ne suivent pas une loi normale. <br>
```{r residu3.2}
ggplot(data = food, aes(y = resi3, x =logtotexp)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi3, x =agedummy)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi3, x =sizedummy)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi3, x =towndummy)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
ggplot(data = food, aes(y = resi3, x =logtotexp*agedummy)) + geom_point(col = 'orange',cex=0.05) + 
    geom_abline(slope = 0)
```
<br> On observe qu'il semblerait y avoir de l'hétéroscédasticité donc nous allons faire le test de Koenker, qui est un test de Breusch-Pagan quand il n'y a pas normalité des résidus, pour regarder si il n'y aurait pas de l'hétéroscédasticité : <br>
```{r}
var.func3 <- lm(resi3^2 ~ logtotexp+logtotexp*agedummy+logtotexp*sizedummy+towndummy, data = food)
summary(var.func3)
kable(qchisq(.95, df = 12), caption="Quantile à 5% du Khi-Deux pour 12 DDL") %>%
  kable_styling(full_width=FALSE) %>% row_spec(0, col="red")
bptest(lm7, studentize = TRUE)
```
Il semblerait donc qu'il y ait de l'hétéroscédasticité dans le modèle simple car la p-value du test est strictement inférieure à 0.001 . On le confirme avec le test de White :
```{r}
ressq3=food$resi3^2
modres3 <- lm(ressq3~logtotexp+logtotexp*agedummy+logtotexp*sizedummy+towndummy, data=food)
summary(modres3)
gmodres3 <- glance(modres3)
Rsq3 <- gmodres3$r.squared
S3 <- gmodres3$df
N3<-nrow(food)
chisq3 <- N3*Rsq3
pval3 <- 1-pchisq(chisq3, S3-1)
kable(pval3, caption="p-value du modèle 7") %>%
  kable_styling(full_width=FALSE) %>% row_spec(0, col="red")
```
La p-value étant très très proche de 0, le test de White nous confirme que l'on a de l'hétéroscédasticité. Donc, nous la corrigeons :
```{r}
coeftest(lm7, vcov = vcovHC(lm7, "HC1"))
varfunc.ols3 <- lm(log(resi3^2) ~ log(logtotexp)+sizedummy+totexp*agedummy+towndummy+totexp*sizedummy, 
                   data = food)
food$varfunc3 <- exp(varfunc.ols3$fitted.values)
attach(food)
lm7_cor<-lm(wfood~logtotexp+logtotexp*agedummy+logtotexp*sizedummy+towndummy,weights=1/sqrt(varfunc3))
summary(lm7_cor)
stargazer(lm7,lm7_cor,type="text")
lm7 %>% vcovHC %>% diag() %>% sqrt()

```
On observe une amélioration du $R^2$ et après la correction des écarts-types estimés, on observe qu'ils ont tous augmenté. De plus, tous les coefficients sont toujours signifcatifs et l'hypothèse H0 des coefficients nuls est toujours rejetée. <br>
Nous allons donc maintenant interpréter ce modèle. On observe qu'une augmentation de 1% des dépenses entrainerait une diminution de 0.119% (<font size=2> $-0.12*log(1.01)$ </font>) de la part du revenu allouée aux dépenses alimentaires. De plus, on remarque que la part des revenus allouée aux dépenses alimentaires augmente de 0.347 quand les personnes de référence dépasse les 30 ans, ce qui pourrait s'expliquer par l'arrivée d'enfants dans le ménage, les demandes alimentaires s'accroient donc avec une ou plusieurs bouches en plus à nourir. Comme vu à l'interprétation du modèle 1, on voit une diminution de 0.025 de la part du revenu allouée à l'alimentation ce qui s'expliquerait certainement par l'augmentation des salaires qui est relativement plus élevée que l'augmentation des prix des biens alimentaires dans les grandes villes. Nous allons maintenant nous intéresser à la variable catégorielle de la taille des ménages. On observe qu'il semblerait que plus le ménage soit grand plus le coefficient de la part du revenu allouée à l'alimentation sera élevé. En effet, il semblerait que pour un ménage de 2 ou 3 personnes, la part du revenu allouée à la consommation serait respectivement de 0.40 et 0.38 tandis que pour un ménage de 4, 5 ou plus de personnes, quasiment la moitié des revenus serait pour les dépenses alimentaires, ce qui s'explique par le fait que la plupart du temps il y a 2 parents et plusieurs enfants, donc plus il y a d'enfants, plus il y a besoin de dépenser dans des denrées alimentaires sans que les revenus du ménage ne soient plus élevés. L'augmentation d'une personne dans le ménage a des effets négatifs sur le logarithme des dépenses totales et donc par la même occasion sur la part du revenu allouée à l'alimentation. Cependant, nous n'observons pas d'effets relativement différents entre les différents coefficients des différentes tailles des ménages. Enfin, on remarque que les personnes de références de plus de 30 ans impactent négativement de 0.0215 le logarithme des dépenses totales et donc l'effet marginal du logarithme des dépenses totales des plus de 30 ans, entraine une baisse de 0.14% (<font size=2> $(-0.119-0.0215)*log(1.01)$ </font>) de la part du revenu allouée à la consommation de biens alimentaires. <br>



En conclusion, on va regarder les différences entre les droites de régression avec comme variable explicative totexp et logtotexp, pour les modèles corrigés de l'hétéroscédasticité et les modèles avec hétéroscédasticité : <br>
```{r}
g <- ggplot(data = food, aes(y = wfood, x = totexp)) + geom_point(col = 'orange')
c<-g + geom_abline(slope = lm1$coefficients[2], intercept = lm1$coefficients[1], col = 'red')+
 geom_abline(slope = lm1_cor$coefficients[2], intercept = lm1_cor$coefficients[1], col = 'green')+
  ggtitle("Modèle 1")
g <- ggplot(data = food, aes(y = wfood, x = logtotexp)) + geom_point(col = 'orange')
d<-g + geom_abline(slope = lm6$coefficients[2], intercept = lm6$coefficients[1], col = 'red')+
 geom_abline(slope = lm6_cor$coefficients[2], intercept = lm6_cor$coefficients[1], col = 'green')+
  ggtitle("Modèle 6")
g <- ggplot(data = food, aes(y = wfood, x = logtotexp)) + geom_point(col = 'orange')
e<-g + geom_abline(slope = lm7$coefficients[2], intercept = lm7$coefficients[1], col = 'red')+
 geom_abline(slope = lm7_cor$coefficients[2], intercept = lm7_cor$coefficients[1], col = 'green')+
  ggtitle("Modèle 7")
grid.arrange(c,d,e,nrow=2,ncol=2)
```
<br> On observe que les droites vertes (après correction) et rouges (avant correction) sont quasiment les mêmes, ce qui pourrait vouloir dire que pour chaque modèle corrigé de l'hétéroscédasticité, celle-ci ne semble pas vraiment disparaitre. On a essayé de corriger l'hétéroscédasticité de nos modèles, mais il semblerait que le problème reste toujours présent.




